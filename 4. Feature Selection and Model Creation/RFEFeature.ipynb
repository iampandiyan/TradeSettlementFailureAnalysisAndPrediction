{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c002953-653b-4074-b7dc-edcdb6b3fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def rfeFeature(indep_X,dep_Y,n):\n",
    "        rfelist=[]\n",
    "        \n",
    "        log_model = LogisticRegression(random_state = 0)\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "       # NB = GaussianNB()\n",
    "        DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "        svc_model = LinearSVC(random_state = 0)\n",
    "        #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        rfemodellist=[log_model,svc_model,RF,DT] \n",
    "        for i in   rfemodellist:\n",
    "            print(i)\n",
    "            log_rfe = RFE(estimator=i, n_features_to_select=n)\n",
    "            log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "            log_rfe_feature=log_fit.transform(indep_X)\n",
    "            print('Feature Column List')\n",
    "            print(log_rfe.get_feature_names_out())\n",
    "            rfelist.append(log_rfe_feature)\n",
    "        return rfelist\n",
    "    \n",
    "\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = LinearSVC(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "   \n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "\n",
    "def rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    rfedataframe=pd.DataFrame(index=['Logistic','SVC','Random','DecisionTree'],columns=['Logistic','SVMl','SVMnl',\n",
    "                                                                                        'KNN','Navie','Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(rfedataframe.index):\n",
    "        rfedataframe.loc[idex,'Logistic']=acclog[number] \n",
    "        rfedataframe.loc[idex,'SVMl']=accsvml[number]\n",
    "        rfedataframe.loc[idex,'SVMnl']=accsvmnl[number] \n",
    "        rfedataframe.loc[idex,'KNN']=accknn[number] \n",
    "        rfedataframe.loc[idex,'Navie']=accnav[number]\n",
    "        rfedataframe.loc[idex,'Decision']=accdes[number]\n",
    "        rfedataframe.loc[idex,'Random']=accrf[number]\n",
    "    return rfedataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e491b1-9477-49f7-8afd-d96c8452c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14900 entries, 0 to 14899\n",
      "Data columns (total 69 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Trade Value                       14900 non-null  float64\n",
      " 1   Trade Volume                      14900 non-null  int64  \n",
      " 2   Counterparty ID                   14900 non-null  int64  \n",
      " 3   Counterparty Risk Score           14900 non-null  float64\n",
      " 4   Counterparty Failures             14900 non-null  int64  \n",
      " 5   Market Volatility                 14900 non-null  float64\n",
      " 6   Liquidity                         14900 non-null  float64\n",
      " 7   Manual Intervention               14900 non-null  int64  \n",
      " 8   Counterparty Failure Rate         14900 non-null  float64\n",
      " 9   Client ID                         14900 non-null  int64  \n",
      " 10  Trade Type_Sell                   14900 non-null  int64  \n",
      " 11  Instrument Type_Derivative        14900 non-null  int64  \n",
      " 12  Instrument Type_Equity            14900 non-null  int64  \n",
      " 13  Settlement Status_Success         14900 non-null  int64  \n",
      " 14  Currency_GBP                      14900 non-null  int64  \n",
      " 15  Currency_INR                      14900 non-null  int64  \n",
      " 16  Currency_JPY                      14900 non-null  int64  \n",
      " 17  Currency_USD                      14900 non-null  int64  \n",
      " 18  Settlement Type_FoP               14900 non-null  int64  \n",
      " 19  ISIN_INE0000014                   14900 non-null  int64  \n",
      " 20  ISIN_INE000002E                   14900 non-null  int64  \n",
      " 21  ISIN_INE0000032                   14900 non-null  int64  \n",
      " 22  ISIN_INE000004J                   14900 non-null  int64  \n",
      " 23  ISIN_INE0000051                   14900 non-null  int64  \n",
      " 24  ISIN_INE000006Z                   14900 non-null  int64  \n",
      " 25  ISIN_INE0000071                   14900 non-null  int64  \n",
      " 26  ISIN_INE000008Y                   14900 non-null  int64  \n",
      " 27  ISIN_INE000009S                   14900 non-null  int64  \n",
      " 28  ISIN_INE0000107                   14900 non-null  int64  \n",
      " 29  ISIN_INE000011Z                   14900 non-null  int64  \n",
      " 30  ISIN_INE0000124                   14900 non-null  int64  \n",
      " 31  ISIN_INE000013O                   14900 non-null  int64  \n",
      " 32  ISIN_INE000014L                   14900 non-null  int64  \n",
      " 33  ISIN_INE000015P                   14900 non-null  int64  \n",
      " 34  ISIN_INE000016P                   14900 non-null  int64  \n",
      " 35  ISIN_INE000017R                   14900 non-null  int64  \n",
      " 36  ISIN_INE0000189                   14900 non-null  int64  \n",
      " 37  ISIN_INE000019P                   14900 non-null  int64  \n",
      " 38  ISIN_INE000020B                   14900 non-null  int64  \n",
      " 39  ISIN_INE000021E                   14900 non-null  int64  \n",
      " 40  ISIN_INE000022Z                   14900 non-null  int64  \n",
      " 41  ISIN_INE000023Y                   14900 non-null  int64  \n",
      " 42  ISIN_INE000024W                   14900 non-null  int64  \n",
      " 43  ISIN_INE0000251                   14900 non-null  int64  \n",
      " 44  ISIN_INE0000260                   14900 non-null  int64  \n",
      " 45  ISIN_INE0000272                   14900 non-null  int64  \n",
      " 46  ISIN_INE000028Z                   14900 non-null  int64  \n",
      " 47  ISIN_INE000029O                   14900 non-null  int64  \n",
      " 48  ISIN_INE000030B                   14900 non-null  int64  \n",
      " 49  ISIN_INE000031V                   14900 non-null  int64  \n",
      " 50  ISIN_INE000032R                   14900 non-null  int64  \n",
      " 51  ISIN_INE0000330                   14900 non-null  int64  \n",
      " 52  ISIN_INE000034S                   14900 non-null  int64  \n",
      " 53  ISIN_INE000035W                   14900 non-null  int64  \n",
      " 54  ISIN_INE0000367                   14900 non-null  int64  \n",
      " 55  ISIN_INE000037F                   14900 non-null  int64  \n",
      " 56  ISIN_INE000038N                   14900 non-null  int64  \n",
      " 57  ISIN_INE000039A                   14900 non-null  int64  \n",
      " 58  ISIN_INE0000402                   14900 non-null  int64  \n",
      " 59  ISIN_INE0000419                   14900 non-null  int64  \n",
      " 60  ISIN_INE000042K                   14900 non-null  int64  \n",
      " 61  ISIN_INE0000432                   14900 non-null  int64  \n",
      " 62  ISIN_INE0000440                   14900 non-null  int64  \n",
      " 63  ISIN_INE000045U                   14900 non-null  int64  \n",
      " 64  ISIN_INE000046I                   14900 non-null  int64  \n",
      " 65  ISIN_INE0000472                   14900 non-null  int64  \n",
      " 66  ISIN_INE0000487                   14900 non-null  int64  \n",
      " 67  ISIN_INE000049P                   14900 non-null  int64  \n",
      " 68  Trade Matched or Not_Not Matched  14900 non-null  int64  \n",
      "dtypes: float64(5), int64(64)\n",
      "memory usage: 7.8 MB\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"TradeSettlementDetails.csv\",index_col=None)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddae681-5360-4112-8918-165054b25d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Column List\n",
      "['Liquidity' 'ISIN_INE0000014' 'ISIN_INE000009S' 'ISIN_INE000011Z'\n",
      " 'ISIN_INE0000189' 'ISIN_INE000035W' 'ISIN_INE000039A' 'ISIN_INE0000402'\n",
      " 'ISIN_INE000045U' 'ISIN_INE0000487']\n",
      "LinearSVC(random_state=0)\n",
      "Feature Column List\n",
      "['Trade Value' 'Trade Volume' 'Counterparty ID' 'Counterparty Risk Score'\n",
      " 'Counterparty Failures' 'Market Volatility' 'Client ID' 'Trade Type_Sell'\n",
      " 'Instrument Type_Equity' 'Settlement Type_FoP']\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Feature Column List\n",
      "['Trade Value' 'Trade Volume' 'Counterparty ID' 'Counterparty Risk Score'\n",
      " 'Counterparty Failures' 'Market Volatility' 'Liquidity'\n",
      " 'Counterparty Failure Rate' 'Client ID' 'Instrument Type_Equity']\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Feature Column List\n",
      "['Trade Value' 'Trade Volume' 'Counterparty ID' 'Counterparty Risk Score'\n",
      " 'Counterparty Failures' 'Market Volatility' 'Liquidity'\n",
      " 'Counterparty Failure Rate' 'Client ID' 'Settlement Type_FoP']\n"
     ]
    }
   ],
   "source": [
    "indep_X=dataset.drop('Settlement Status_Success', axis=1)\n",
    "dep_Y=dataset['Settlement Status_Success']\n",
    "rfelist=rfeFeature(indep_X,dep_Y,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec284cfb-ec9c-4122-81c5-48a39cf17fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Pandiyan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.550336</td>\n",
       "      <td>0.550604</td>\n",
       "      <td>0.545503</td>\n",
       "      <td>0.509262</td>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.508188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.539329</td>\n",
       "      <td>0.512483</td>\n",
       "      <td>0.550067</td>\n",
       "      <td>0.504966</td>\n",
       "      <td>0.493691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.542013</td>\n",
       "      <td>0.502819</td>\n",
       "      <td>0.545235</td>\n",
       "      <td>0.496376</td>\n",
       "      <td>0.497987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.551409</td>\n",
       "      <td>0.54443</td>\n",
       "      <td>0.525101</td>\n",
       "      <td>0.544698</td>\n",
       "      <td>0.492349</td>\n",
       "      <td>0.496644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision  \\\n",
       "Logistic      0.550336  0.550604  0.545503  0.509262  0.551409  0.503893   \n",
       "SVC           0.551409  0.551409  0.539329  0.512483  0.550067  0.504966   \n",
       "Random        0.551409  0.551409  0.542013  0.502819  0.545235  0.496376   \n",
       "DecisionTree  0.551409  0.551409   0.54443  0.525101  0.544698  0.492349   \n",
       "\n",
       "                Random  \n",
       "Logistic      0.508188  \n",
       "SVC           0.493691  \n",
       "Random        0.497987  \n",
       "DecisionTree  0.496644  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "\n",
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n",
    "result=rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54004e3a-b3ff-4b41-b43f-4ea86ed3248b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
